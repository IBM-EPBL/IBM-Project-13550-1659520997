{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f75afcb",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c8a80b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d0ffa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='1luKH6odwgL64J_imfwZ92uWTIEdmQgqio04U6KSzhrp',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'realtimecommunicationpoweredbyaif-donotdelete-pr-txswq4p8o2phjc'\n",
    "object_key = 'conversation engine for deaf and dumb.zip'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ebd8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfc85c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDataset\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "faaf9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad5fd89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e52c3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8a2bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f42f65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2b270d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"/home/wsuser/work/Dataset/training_set\",target_size=(64,64),\n",
    "                                          class_mode=\"categorical\",batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e699172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r\"/home/wsuser/work/Dataset/test_set\",target_size=(64,64),\n",
    "                                                            class_mode=\"categorical\",batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10140cd8",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb320f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8cbb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),activation=\"relu\",input_shape=(64,64,3)))\n",
    "#No of feature detectors, size of feature detector, image size, activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a58367",
   "metadata": {},
   "source": [
    "**add the Pooling Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69964eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe386bf9",
   "metadata": {},
   "source": [
    "**Adding the flatten Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21e5e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d1da6",
   "metadata": {},
   "source": [
    "**Adding the Dense Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e310c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200,activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10831f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ea0a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89533c",
   "metadata": {},
   "source": [
    "**Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06112150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf89fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ab75268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c92062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318544ba",
   "metadata": {},
   "source": [
    "**Fit and Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69733a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "525/525 [==============================] - 81s 153ms/step - loss: 0.2869 - accuracy: 0.9035 - val_loss: 0.2433 - val_accuracy: 0.9511\n",
      "Epoch 2/9\n",
      "525/525 [==============================] - 79s 150ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.1269 - val_accuracy: 0.9764\n",
      "Epoch 3/9\n",
      "525/525 [==============================] - 81s 154ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.1501 - val_accuracy: 0.9756\n",
      "Epoch 4/9\n",
      "525/525 [==============================] - 78s 149ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.2076 - val_accuracy: 0.9702\n",
      "Epoch 5/9\n",
      "525/525 [==============================] - 80s 151ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.2317 - val_accuracy: 0.9787\n",
      "Epoch 6/9\n",
      "525/525 [==============================] - 79s 150ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 0.2584 - val_accuracy: 0.9711\n",
      "Epoch 7/9\n",
      "525/525 [==============================] - 80s 151ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1855 - val_accuracy: 0.9778\n",
      "Epoch 8/9\n",
      "525/525 [==============================] - 79s 150ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.4316 - val_accuracy: 0.9724\n",
      "Epoch 9/9\n",
      "525/525 [==============================] - 80s 152ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.5889 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9106a4a60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,epochs=9,validation_data=x_test,steps_per_epoch=len(x_train),validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83265e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('signlanguageasl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6381be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson_machine_learning_client\n",
      "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
      "\u001b[K     |████████████████████████████████| 538 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.11.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.18.21)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (4.62.3)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.26.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2022.9.24)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.3.4)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.8.9)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (1.21.41)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (1.15.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (2.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (1.20.3)\n",
      "Installing collected packages: watson-machine-learning-client\n",
      "Successfully installed watson-machine-learning-client-1.0.391\n"
     ]
    }
   ],
   "source": [
    "!pip install watson_machine_learning_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90696921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "url_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": \"8BHLfgyhaWkUcepYAr4BCvJI1BFlWppbdHrvRE8w1D99\"\n",
    "}\n",
    "client = APIClient(url_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "690cb1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ibm_watson_machine_learning.client.APIClient at 0x7fa9106a43a0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "424ec593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b077ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space UID = 1d7c9d04-944f-447d-a52a-8e3f7c30e562\n"
     ]
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client, 'sign_language')\n",
    "print(\"space UID = \" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8299bcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d408f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------  ------------------------------------  ----\n",
      "NAME                             ASSET_ID                              TYPE\n",
      "default_py3.6                    0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "kernel-spark3.2-scala2.12        020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
      "pytorch-onnx_1.3-py3.7-edt       069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6          09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12       09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "pytorch-onnx_rt22.1-py3.9        0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
      "ai-function_0.1-py3.6            0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                       0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod     1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6                10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl        111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "autoai-kb_rt22.2-py3.10          125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
      "runtime-22.1-py3.9               12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
      "scikit-learn_0.22-py3.6          154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                     1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6           1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "kernel-spark3.3-r3.6             1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
      "pytorch-onnx_rt22.1-py3.9-edt    1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
      "tensorflow_2.1-py3.6             1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "spark-mllib_3.2                  20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
      "tensorflow_2.4-py3.8-horovod     217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "runtime-22.1-py3.9-cuda          26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
      "do_py3.8                         295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8              2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6            2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "kernel-spark3.3-py3.9            2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
      "pytorch_1.2-py3.6                2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                  2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt       32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37             36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                  390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "autoai-ts_rt22.2-py3.10          396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
      "xgboost_0.82-py3.6               39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt       40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "pytorch-onnx_rt22.2-py3.10       40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
      "default_r36py38                  41c247d3-45f8-5a71-b065-8580229facf0  base\n",
      "autoai-ts_rt22.1-py3.9           4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
      "autoai-obm_3.0                   42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "pmml-3.0_4.3                     493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
      "spark-mllib_2.4-r_3.6            49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6               4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6           50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8              52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11       55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                  5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                   5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1                5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                       5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "autoai-kb_3.1-py3.7              632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "pytorch-onnx_1.7-py3.8           634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
      "spark-mllib_2.3-r_3.6            6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\n",
      "tensorflow_2.4-py3.7             65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\n",
      "spss-modeler_18.2                687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n",
      "pytorch-onnx_1.2-py3.6           692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\n",
      "spark-mllib_2.3-scala_2.11       7963efe5-bbec-417e-92cf-0574e21b4e8d  base\n",
      "spark-mllib_2.4-py37             7abc992b-b685-532b-a122-a396a3cdbaab  base\n",
      "caffe_1.0-py3.6                  7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\n",
      "pytorch-onnx_1.7-py3.7           812c6631-42b7-5613-982b-02098e6c909c  base\n",
      "cuda-py3.6                       82c79ece-4d12-40e6-8787-a7b9e0f62770  base\n",
      "tensorflow_1.15-py3.6-horovod    8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\n",
      "hybrid_0.1                       8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\n",
      "pytorch-onnx_1.3-py3.7           8d5d8a87-a912-54cf-81ec-3914adaa988d  base\n",
      "caffe-ibm_1.0-py3.6              8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\n",
      "spss-modeler_17.1                902d0051-84bd-4af6-ab6b-8f6aa6fdeabb  base\n",
      "do_12.10                         9100fd72-8159-4eb9-8a0b-a87e12eefa36  base\n",
      "do_py3.7                         9447fa8b-2051-4d24-9eef-5acb0e3c59f8  base\n",
      "spark-mllib_3.0-r_3.6            94bb6052-c837-589d-83f1-f4142f219e32  base\n",
      "cuda-py3.7-opence                94e9652b-7f2d-59d5-ba5a-23a414ea488f  base\n",
      "nlp-py3.8                        96e60351-99d4-5a1c-9cc0-473ac1b5a864  base\n",
      "cuda-py3.7                       9a44990c-1aa1-4c7d-baf8-c4099011741c  base\n",
      "hybrid_0.2                       9b3f9040-9cee-4ead-8d7a-780600f542f7  base\n",
      "spark-mllib_3.0-py38             9f7a8fc1-4d3c-5e65-ab90-41fa8de2d418  base\n",
      "autoai-kb_3.3-py3.7              a545cca3-02df-5c61-9e88-998b09dc79af  base\n",
      "spark-mllib_3.0-py39             a6082a27-5acc-5163-b02c-6b96916eb5e0  base\n",
      "runtime-22.1-py3.9-do            a7e7dbf1-1d03-5544-994d-e5ec845ce99a  base\n",
      "default_py3.8                    ab9e1b80-f2ce-592c-a7d2-4f2344f77194  base\n",
      "tensorflow_rt22.1-py3.9          acd9c798-6974-5d2f-a657-ce06e986df4d  base\n",
      "kernel-spark3.2-py3.9            ad7033ee-794e-58cf-812e-a95f4b64b207  base\n",
      "autoai-obm_2.0 with Spark 3.0    af10f35f-69fa-5d66-9bf5-acb58434263a  base\n",
      "default_py3.7_opence             c2057dd4-f42c-5f77-a02f-72bdbd3282c9  base\n",
      "tensorflow_2.1-py3.7             c4032338-2a40-500a-beef-b01ab2667e27  base\n",
      "do_py3.7_opence                  cc8f8976-b74a-551a-bb66-6377f8d865b4  base\n",
      "spark-mllib_3.3                  d11f2434-4fc7-58b7-8a62-755da64fdaf8  base\n",
      "autoai-kb_3.0-py3.6              d139f196-e04b-5d8b-9140-9a10ca1fa91a  base\n",
      "spark-mllib_3.0-py36             d82546d5-dd78-5fbb-9131-2ec309bc56ed  base\n",
      "autoai-kb_3.4-py3.8              da9b39c3-758c-5a4f-9cfd-457dd4d8c395  base\n",
      "kernel-spark3.2-r3.6             db2fe4d6-d641-5d05-9972-73c654c60e0a  base\n",
      "autoai-kb_rt22.1-py3.9           db6afe93-665f-5910-b117-d879897404d9  base\n",
      "tensorflow_rt22.1-py3.9-horovod  dda170cc-ca67-5da7-9b7a-cf84c6987fae  base\n",
      "autoai-ts_1.0-py3.7              deef04f0-0c42-5147-9711-89f9904299db  base\n",
      "tensorflow_2.1-py3.7-horovod     e384fce5-fdd1-53f8-bc71-11326c9c635f  base\n",
      "default_py3.7                    e4429883-c883-42b6-87a8-f419d64088cd  base\n",
      "do_22.1                          e51999ba-6452-5f1f-8287-17228b88b652  base\n",
      "autoai-obm_3.2                   eae86aab-da30-5229-a6a6-1d0d4e368983  base\n",
      "tensorflow_rt22.2-py3.10         f65bd165-f057-55de-b5cb-f97cf2c0f393  base\n",
      "do_20.1                          f686cdd9-7904-5f9d-a732-01b0d6b10dc5  base\n",
      "pytorch-onnx_rt22.2-py3.10-edt   f8a05d07-e7cd-57bb-a10b-23f1d4b837ac  base\n",
      "scikit-learn_0.19-py3.6          f963fa9d-4bb7-5652-9c5d-8d9289ef6ad9  base\n",
      "tensorflow_2.4-py3.8             fe185c44-9a99-5425-986b-59bd1d2eda46  base\n",
      "-------------------------------  ------------------------------------  ----\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f165e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7f7a1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acd9c798-6974-5d2f-a657-ce06e986df4d'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89a907ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDataset\u001b[0m/  signlanguageasl.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12b401f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signlanguageasl.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf image-Classification-model.tgz signlanguageasl.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0bd3bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.store_model(model='image-Classification-model.tgz',meta_props={\n",
    "    client.repository.ModelMetaNames.NAME:'CNN',\n",
    "    client.repository.ModelMetaNames.TYPE:\"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22aaffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method is deprecated, please use get_model_id()\n"
     ]
    }
   ],
   "source": [
    "model_id = client.repository.get_model_uid(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "323533ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38f4a808-0736-40fa-82dc-43e9a817b59e'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b955821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'my_model.tar.gz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/my_model.tar.gz'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.download(model_id, 'my_model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "168f18a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDataset\u001b[0m/  image-Classification-model.tgz  my_model.tar.gz  signlanguageasl.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b4ee1",
   "metadata": {},
   "source": [
    "# Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e34d269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "290f28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "597bec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'C:\\Users\\hemam\\Downloads\\signlanguageasl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68078a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAACMElEQVR4nO2aO47CMBCGzSMi4QSGBlEiWi4BEhIVZU7AATgCBRUN1FSUdByBJgWnoKGgTESIvEW0LLuFk3nESZZ8ZTR2/l/jsZ0BISoqKioqKj4ApZRSyrbtvIWgOJ/P6pv9fp+3nF/U0gQppX6NqaUaZYZ63gKofKSBPysqX5AZuFwuvu+/KjsMQ15ZnJxOJ0Ug3nlt235/2Gw2ueQlZ6DValFeECfK9/33h2EYKqXa7bYQQkrpeZ6UUkqJmD95QzS54h3HCYIANCTBgPl6DYLAcZz08bolNBwOyXrAQG8rOgOLxYImBkMURaD4wh1kjUYDFF84A1B0Bo7HoykZP0B3IZ2B2WxG0oLCsixQvM6A53k0MRigtxKdgdFoRBNjgn9dxLnAeZCVgtIb0F3mLMt6PB7GpLwANQ10GdhsNmQxmVO467RgzEApSDBwOBzM6ECTnKzr9drpdAxIiYmiCPTJn7yEut0uQQ+Y7XYLik9bLsaqGdp4TVvEZhq66/UaOgQmy0AesspAzHw+B8VDcV030/mFEGI6nVI6jXrqdSPn0mQyyciACfUx4/GYXf3tdjNnQGSQB2hLiwHeeuj1eqYNxHAZwLXXGXBdl8UA7u085yv69e/gDnuefXe5XLLMg4DthkNPQp4ZyJHKABODwQA3kM3AarXimgoE52cKsY5LX8S4k5jTwG63owy/3+9cSpD0+/2yXiVeUMrg+XxCfyAThTIgUHXMXMTEViTiX5Ff+UBJ3glErx4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =image.load_img(r'C:\\Users\\hemam\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set\\A\\55.png',target_size = (64,64))\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f19ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70ecc286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756e3e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b298084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19d91107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 390ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b37917f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f993ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\"]\n",
    "pred_id = pred_prob.argmax(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "952979ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0ca4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the alphabet is   A\n"
     ]
    }
   ],
   "source": [
    "print(\"the alphabet is  \",str(class_name[pred_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca22e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
